# Papers related to text image on NeurIPS 2023!


### prompt

[Improving CLIP Training with Language Rewrites](https://openreview.net/pdf?id=SVjDiiVySh)

[Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning](https://openreview.net/pdf?id=2b9aY2NgXE)

[Align Your Prompts: Test-Time Prompting with Distribution Alignment for Zero-Shot Generalization](https://openreview.net/pdf?id=CusNOTRkQw)

[UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models](https://openreview.net/pdf?id=VMAgvbBBts)

[The CLIP Model is Secretly an Image-to-Prompt Converter](https://openreview.net/pdf?id=lHa7gFbmvS)

[Optimizing Prompts for Text-to-Image Generation](https://openreview.net/pdf?id=BsZNWXD3a1)

[Dynamic Prompt Learning: Addressing Cross-Attention Leakage for Text-Based Image Editing](https://openreview.net/pdf?id=5UXXhVI08r)

[Visual Instruction Inversion: Image Editing via Image Prompting](https://openreview.net/pdf?id=l9BsCh8ikK)

[Tuning Multi-mode Token-level Prompt Alignment across Modalities](https://openreview.net/pdf?id=A253n2EXCd)

[SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models](https://openreview.net/pdf?id=EhdNQiOWgQ)

[LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning](https://openreview.net/pdf?id=UjtiLdXGMC)

[The Rise of AI Language Pathologists: Exploring Two-level Prompt Learning for Few-shot Weakly-supervised Whole Slide Image Classification](https://openreview.net/pdf?id=mSDfBXr8Py)

[Fine-Grained Visual Prompting](https://openreview.net/pdf?id=l6R4Go3noz)

### adaptation
[Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models](https://openreview.net/pdf?id=4d8dO5sAeM)

[CLIP4HOI: Towards Adapting CLIP for Practical Zero-Shot HOI Detection](https://openreview.net/pdf?id=nqIIWnwe73)

[Meta-Adapter: An Online Few-shot Learner for Vision-Language Model](https://openreview.net/pdf?id=Ts0d8PvTeB)

[GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph](https://openreview.net/pdf?id=YmEDnMynuO)








### text-to-image generation
[ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation](https://openreview.net/pdf?id=JVzeOYEx6d)

[Subject-driven Text-to-Image Generation via Apprenticeship Learning](https://arxiv.org/pdf/2304.00186.pdf)

[CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation](https://openreview.net/pdf?id=z9d9DsjAPH)

[T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation](https://openreview.net/pdf?id=weHBzTLXpH)

[Norm-guided latent space exploration for text-to-image generation](https://openreview.net/pdf?id=f56xMRb7Vt)

[Cocktail: Mixing Multi-Modality Control for Text-Conditional Image Generation](https://openreview.net/pdf?id=sQBGVw5qH9)

[DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models](https://openreview.net/pdf?id=8OTPepXzeh)

[StyleDrop: Text-to-Image Synthesis of Any Style](https://openreview.net/pdf?id=KoaFh16uOc)

[RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths](https://openreview.net/pdf?id=jUdZCcoOu3)

[Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models](https://openreview.net/pdf?id=VgQw8zXrH8)

[Training-free Diffusion Model Adaptation for Variable-Sized Text-to-Image Synthesis](https://openreview.net/pdf?id=4ULTSBBY4U)

[Conditional Score Guidance for Text-Driven Image-to-Image Translation](https://openreview.net/pdf?id=cBS5CU96Jq)

[BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing](https://openreview.net/pdf?id=g6We1SwaY9)

[TextDiffuser: Diffusion Models as Text Painters](https://openreview.net/pdf?id=ke3RgcDmfO)

[Controlling Text-to-Image Diffusion by Orthogonal Finetuning](https://openreview.net/pdf?id=K30wTdIIYc)




### general boosting

[Bootstrapping Vision-Language Learning with Decoupled Language Pre-training](https://openreview.net/pdf?id=8Kch0ILfQH)

[LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections](https://openreview.net/pdf?id=elPtHcfjpH)

[Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with CLIP](https://openreview.net/pdf?id=NXLjaYdgaL)

[A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)](https://openreview.net/pdf?id=wMNpMe0vp3)

[Cross-modal Active Complementary Learning with Self-refining Correspondence](https://openreview.net/pdf?id=UBBeUjTja8)

[Test-Time Distribution Normalization for Contrastively Learned Visual-language Models](https://openreview.net/pdf?id=VKbEO2eh5w)

[Three Towers: Flexible Contrastive Learning with Pretrained Image Models](https://openreview.net/pdf?id=LSYQB4CwD3)

[An Inverse Scaling Law for CLIP Training](https://openreview.net/pdf?id=LMU2RNwdh2)

[Geodesic Multi-Modal Mixup for Robust Fine-Tuning](https://openreview.net/pdf?id=iAAXq60Bw1)

[ChatGPT-Powered Hierarchical Comparisons for Image Classification](https://openreview.net/pdf?id=GTYaYNsFyv)


### others

[Learning Mask-aware CLIP Representations for Zero-Shot Segmentation](https://openreview.net/pdf?id=K1Uzj8tuwd)

[What Makes Good Examples for Visual In-Context Learning?](https://openreview.net/pdf?id=pIXTMrBe7f)

[Towards Consistent Video Editing with Text-to-Image Diffusion Models](https://openreview.net/pdf?id=RNVwm4BzXO)

[Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP](https://openreview.net/pdf?id=83LJRUzXWj)

[VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks](https://openreview.net/pdf?id=Vx1JadlOIt)

[A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)](https://openreview.net/pdf?id=wMNpMe0vp3)









